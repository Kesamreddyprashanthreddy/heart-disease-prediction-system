{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9cf6788",
   "metadata": {},
   "source": [
    "# Complete End-to-End Machine Learning Pipeline\n",
    "\n",
    "This notebook demonstrates a production-ready machine learning pipeline including:\n",
    "- Data cleaning and preprocessing\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Feature engineering\n",
    "- Model training and evaluation\n",
    "- Model deployment preparation\n",
    "\n",
    "## Project Structure\n",
    "```\n",
    "machine-learning-pipeline/\n",
    "â”‚â”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ raw/\n",
    "â”‚   â”œâ”€â”€ processed/\n",
    "â”‚â”€â”€ notebooks/\n",
    "â”‚â”€â”€ src/\n",
    "â”‚   â”œâ”€â”€ data_cleaning.py\n",
    "â”‚   â”œâ”€â”€ feature_engineering.py\n",
    "â”‚   â”œâ”€â”€ model_training.py\n",
    "â”‚   â”œâ”€â”€ model_evaluation.py\n",
    "â”‚   â””â”€â”€ utils.py\n",
    "â”‚â”€â”€ models/\n",
    "â”‚â”€â”€ deployment/\n",
    "â”‚â”€â”€ plots/\n",
    "â”‚â”€â”€ docs/\n",
    "â”‚â”€â”€ README.md\n",
    "â”‚â”€â”€ requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2bc3b5",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Library Imports\n",
    "\n",
    "First, let's import all necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                           confusion_matrix, classification_report, roc_auc_score,\n",
    "                           mean_squared_error, mean_absolute_error, r2_score)\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Configure settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf0c225",
   "metadata": {},
   "source": [
    "## 2. Project Structure Creation\n",
    "\n",
    "Let's create the required directory structure for our ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structure\n",
    "def create_project_structure():\n",
    "    \"\"\"Create the complete project directory structure.\"\"\"\n",
    "    directories = [\n",
    "        '../data/raw',\n",
    "        '../data/processed',\n",
    "        '../src',\n",
    "        '../models',\n",
    "        '../deployment',\n",
    "        '../plots',\n",
    "        '../docs'\n",
    "    ]\n",
    "    \n",
    "    for directory in directories:\n",
    "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"âœ“ Created/verified directory: {directory}\")\n",
    "\n",
    "# Create the project structure\n",
    "create_project_structure()\n",
    "\n",
    "# Add src to path for imports\n",
    "src_path = os.path.abspath('../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "print(\"\\nâœ“ Project structure created successfully!\")\n",
    "print(\"âœ“ Source directory added to Python path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c6e92",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Initial Exploration\n",
    "\n",
    "We'll create a sample dataset for demonstration, then load and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset for demonstration\n",
    "def create_sample_dataset(filepath, n_samples=500):\n",
    "    \"\"\"Create a sample dataset for loan approval prediction.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = {\n",
    "        'age': np.random.randint(18, 80, n_samples),\n",
    "        'income': np.random.normal(50000, 20000, n_samples),\n",
    "        'education_years': np.random.randint(8, 20, n_samples),\n",
    "        'experience': np.random.randint(0, 40, n_samples),\n",
    "        'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'], n_samples),\n",
    "        'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "        'married': np.random.choice(['Yes', 'No'], n_samples),\n",
    "        'credit_score': np.random.randint(300, 850, n_samples),\n",
    "        'loan_amount': np.random.normal(200000, 100000, n_samples),\n",
    "        'employment_type': np.random.choice(['Full-time', 'Part-time', 'Self-employed', 'Unemployed'], n_samples)\n",
    "    }\n",
    "    \n",
    "    # Create target variable (loan approval) based on logical rules\n",
    "    df = pd.DataFrame(data)\n",
    "    df['loan_approved'] = (\n",
    "        (df['income'] > 40000) & \n",
    "        (df['credit_score'] > 650) & \n",
    "        (df['employment_type'].isin(['Full-time', 'Self-employed']))\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Add some missing values randomly\n",
    "    missing_cols = ['income', 'credit_score', 'education_years']\n",
    "    for col in missing_cols:\n",
    "        missing_idx = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)\n",
    "        df.loc[missing_idx, col] = np.nan\n",
    "    \n",
    "    # Add some duplicates\n",
    "    duplicate_rows = df.sample(n=int(0.02 * len(df)))\n",
    "    df = pd.concat([df, duplicate_rows], ignore_index=True)\n",
    "    \n",
    "    # Save the dataset\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Sample dataset created with {len(df)} rows and saved to {filepath}\")\n",
    "    return df\n",
    "\n",
    "# Create sample dataset\n",
    "sample_path = \"../data/raw/sample_data.csv\"\n",
    "sample_df = create_sample_dataset(sample_path)\n",
    "\n",
    "print(f\"\\nDataset created successfully!\")\n",
    "print(f\"Shape: {sample_df.shape}\")\n",
    "print(f\"Columns: {list(sample_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad72488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the dataset\n",
    "df = pd.read_csv(\"../data/raw/sample_data.csv\")\n",
    "\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n=== COLUMN INFORMATION ===\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n=== FIRST FEW ROWS ===\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n=== STATISTICAL SUMMARY ===\")\n",
    "display(df.describe(include='all'))\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "print(missing_summary[missing_summary['Missing Count'] > 0])\n",
    "\n",
    "print(\"\\n=== DUPLICATE ROWS ===\")\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n=== TARGET VARIABLE DISTRIBUTION ===\")\n",
    "if 'loan_approved' in df.columns:\n",
    "    print(df['loan_approved'].value_counts())\n",
    "    print(f\"\\nApproval rate: {df['loan_approved'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edafc422",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning Pipeline\n",
    "\n",
    "Now we'll implement comprehensive data cleaning using our modular approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc149a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom data cleaning module\n",
    "from data_cleaning import DataCleaner\n",
    "\n",
    "# Initialize data cleaner\n",
    "cleaner = DataCleaner()\n",
    "\n",
    "# Run complete data cleaning pipeline\n",
    "input_path = \"../data/raw/sample_data.csv\"\n",
    "output_path = \"../data/processed/cleaned_data.csv\"\n",
    "\n",
    "cleaned_df = cleaner.clean_data(\n",
    "    filepath=input_path,\n",
    "    output_path=output_path,\n",
    "    missing_strategy={'income': 'median', 'credit_score': 'median'},\n",
    "    outlier_method='iqr',\n",
    "    outlier_action='cap'\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Data cleaning complete!\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {cleaned_df.shape}\")\n",
    "print(f\"Cleaned data saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8809dd",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's perform comprehensive EDA to understand our cleaned data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd49095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EDA module\n",
    "from eda import EDAAnalyzer\n",
    "\n",
    "# Initialize EDA analyzer\n",
    "eda_analyzer = EDAAnalyzer(plots_dir=\"../plots\")\n",
    "\n",
    "# Generate comprehensive EDA report\n",
    "eda_report = eda_analyzer.generate_eda_report(cleaned_df, target_col='loan_approved')\n",
    "\n",
    "print(\"âœ“ EDA analysis complete!\")\n",
    "print(f\"Generated plots: {eda_report['plots_generated']}\")\n",
    "print(\"\\nCheck the '../plots' directory for all visualizations!\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n=== SUMMARY STATISTICS ===\")\n",
    "summary_stats = eda_analyzer.generate_summary_statistics(cleaned_df)\n",
    "print(f\"Dataset shape: {summary_stats['dataset_info']['shape']}\")\n",
    "print(f\"Missing values: {summary_stats['dataset_info']['missing_values']}\")\n",
    "print(f\"Duplicate rows: {summary_stats['dataset_info']['duplicates']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a22225",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "Now we'll apply comprehensive feature engineering transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d62b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import feature engineering module\n",
    "from feature_engineering import FeatureEngineer\n",
    "\n",
    "# Initialize feature engineer\n",
    "feature_engineer = FeatureEngineer(models_dir=\"../models\")\n",
    "\n",
    "# Run complete feature engineering pipeline\n",
    "X_train, X_test, y_train, y_test = feature_engineer.engineer_features(\n",
    "    cleaned_df, \n",
    "    target_col='loan_approved',\n",
    "    scaling_method='standard',\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Feature engineering complete!\")\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Original features: {len(cleaned_df.columns)}\")\n",
    "print(f\"Engineered features: {len(X_train.columns)}\")\n",
    "print(f\"Features added: {len(X_train.columns) - len(cleaned_df.columns)}\")\n",
    "\n",
    "# Save processed data\n",
    "X_train.to_csv(\"../data/processed/X_train.csv\", index=False)\n",
    "X_test.to_csv(\"../data/processed/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"../data/processed/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"../data/processed/y_test.csv\", index=False)\n",
    "\n",
    "print(\"âœ“ Processed data saved to ../data/processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3294610",
   "metadata": {},
   "source": [
    "## 7. Model Training\n",
    "\n",
    "We'll train multiple models and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635622b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model training module\n",
    "from model_training import ModelTrainer\n",
    "\n",
    "# Initialize model trainer\n",
    "trainer = ModelTrainer(models_dir=\"../models\")\n",
    "\n",
    "# Train all models\n",
    "training_results = trainer.train_all_models(\n",
    "    X_train, y_train, \n",
    "    use_grid_search=True, \n",
    "    cv_folds=5\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Model training complete!\")\n",
    "print(f\"Models trained: {len(training_results)}\")\n",
    "\n",
    "# Display training results summary\n",
    "for model_name, result in training_results.items():\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  âœ“ Best CV Score: {result['best_cv_score']:.4f}\")\n",
    "        print(f\"  âœ“ Best Parameters: {result['best_params']}\")\n",
    "    else:\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  âœ— Training failed: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "# Quick model comparison on test set\n",
    "comparison = trainer.compare_models_quick(X_test, y_test)\n",
    "print(f\"\\n=== MODEL COMPARISON ON TEST SET ===\")\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f2442c",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Comparison\n",
    "\n",
    "Let's perform comprehensive model evaluation with detailed metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9aae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model evaluation module\n",
    "from model_evaluation import ModelEvaluator\n",
    "\n",
    "# Initialize model evaluator\n",
    "evaluator = ModelEvaluator(models_dir=\"../models\", plots_dir=\"../plots\")\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "evaluation_results = evaluator.evaluate_all_models(X_test, y_test)\n",
    "\n",
    "print(f\"âœ“ Model evaluation complete!\")\n",
    "print(f\"Models evaluated: {len(evaluation_results)}\")\n",
    "\n",
    "# Display detailed results\n",
    "for model_name, result in evaluation_results.items():\n",
    "    print(f\"\\n=== {model_name.upper()} EVALUATION ===\")\n",
    "    metrics = result['metrics']\n",
    "    \n",
    "    if result['problem_type'] == 'classification':\n",
    "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
    "        if metrics['roc_auc']:\n",
    "            print(f\"ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
    "    else:\n",
    "        print(f\"RMSE: {metrics['rmse']:.4f}\")\n",
    "        print(f\"MAE: {metrics['mae']:.4f}\")\n",
    "        print(f\"RÂ² Score: {metrics['r2_score']:.4f}\")\n",
    "\n",
    "print(f\"\\nâœ“ Evaluation plots saved to: ../plots/\")\n",
    "print(f\"âœ“ Detailed results saved to: ../models/evaluation_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5939746e",
   "metadata": {},
   "source": [
    "## 9. Best Model Selection and Saving\n",
    "\n",
    "Let's identify and save the best performing model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d6a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model information is already saved by the evaluator\n",
    "# Let's load and display the best model info\n",
    "\n",
    "with open(\"../models/best_model_info.json\", \"r\") as f:\n",
    "    best_model_info = json.load(f)\n",
    "\n",
    "print(\"=== BEST MODEL INFORMATION ===\")\n",
    "for problem_type, info in best_model_info.items():\n",
    "    print(f\"\\n{problem_type.upper()}:\")\n",
    "    print(f\"  Best Model: {info['model_name']}\")\n",
    "    for metric, value in info['all_metrics'].items():\n",
    "        if value is not None:\n",
    "            print(f\"  {metric.title()}: {value:.4f}\")\n",
    "\n",
    "# Verify that best model is saved\n",
    "import os\n",
    "best_model_path = \"../models/best_model.pkl\"\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"\\nâœ“ Best model saved at: {best_model_path}\")\n",
    "    \n",
    "    # Load and test the best model\n",
    "    with open(best_model_path, \"rb\") as f:\n",
    "        best_model = pickle.load(f)\n",
    "    \n",
    "    # Make a sample prediction\n",
    "    sample_prediction = best_model.predict(X_test.head(1))\n",
    "    print(f\"âœ“ Best model loaded and tested successfully\")\n",
    "    print(f\"Sample prediction: {sample_prediction[0]}\")\n",
    "else:\n",
    "    print(\"âœ— Best model file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e473e8",
   "metadata": {},
   "source": [
    "## 10. Flask API Deployment Setup\n",
    "\n",
    "Let's set up our Flask API for model deployment. The API files are already created in the deployment folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Flask API is already created in ../deployment/app.py\n",
    "# Let's verify the deployment files exist and show how to use them\n",
    "\n",
    "deployment_files = [\n",
    "    \"../deployment/app.py\",\n",
    "    \"../deployment/test_api.py\"\n",
    "]\n",
    "\n",
    "print(\"=== DEPLOYMENT FILES STATUS ===\")\n",
    "for file_path in deployment_files:\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"âœ“ {file_path} exists\")\n",
    "    else:\n",
    "        print(f\"âœ— {file_path} missing\")\n",
    "\n",
    "print(f\"\\n=== API USAGE INSTRUCTIONS ===\")\n",
    "print(f\"\"\"\n",
    "To start the Flask API:\n",
    "1. Navigate to the deployment directory:\n",
    "   cd ../deployment\n",
    "\n",
    "2. Run the Flask application:\n",
    "   python app.py\n",
    "\n",
    "3. The API will be available at: http://localhost:5000\n",
    "\n",
    "Available endpoints:\n",
    "- GET  /health          - Health check\n",
    "- GET  /model_info      - Model information  \n",
    "- POST /predict         - Make predictions\n",
    "- GET  /predict_sample  - Test with sample data\n",
    "\n",
    "To test the API:\n",
    "- In another terminal, run: python test_api.py\n",
    "\"\"\")\n",
    "\n",
    "# Create a sample request for demonstration\n",
    "sample_request = {\n",
    "    \"data\": {\n",
    "        \"age\": 35,\n",
    "        \"income\": 55000,\n",
    "        \"education_years\": 16,\n",
    "        \"experience\": 10,\n",
    "        \"city\": \"New York\",\n",
    "        \"gender\": \"Female\",\n",
    "        \"married\": \"Yes\",\n",
    "        \"credit_score\": 720,\n",
    "        \"loan_amount\": 200000,\n",
    "        \"employment_type\": \"Full-time\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nExample API request body:\")\n",
    "print(json.dumps(sample_request, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a89c62a",
   "metadata": {},
   "source": [
    "## 11. Testing the Complete Pipeline\n",
    "\n",
    "Let's verify that our complete ML pipeline works end-to-end and generate the final project files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae14e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all pipeline components and files\n",
    "import glob\n",
    "\n",
    "print(\"=== PIPELINE VERIFICATION ===\")\n",
    "\n",
    "# Check data files\n",
    "data_files = [\n",
    "    \"../data/raw/sample_data.csv\",\n",
    "    \"../data/processed/cleaned_data.csv\",\n",
    "    \"../data/processed/X_train.csv\", \n",
    "    \"../data/processed/X_test.csv\",\n",
    "    \"../data/processed/y_train.csv\",\n",
    "    \"../data/processed/y_test.csv\"\n",
    "]\n",
    "\n",
    "print(f\"\\nData Files:\")\n",
    "for file_path in data_files:\n",
    "    if os.path.exists(file_path):\n",
    "        size = os.path.getsize(file_path)\n",
    "        print(f\"âœ“ {file_path} ({size:,} bytes)\")\n",
    "    else:\n",
    "        print(f\"âœ— {file_path} missing\")\n",
    "\n",
    "# Check model files\n",
    "model_files = glob.glob(\"../models/*.pkl\") + glob.glob(\"../models/*.json\")\n",
    "print(f\"\\nModel Files ({len(model_files)} files):\")\n",
    "for file_path in sorted(model_files):\n",
    "    size = os.path.getsize(file_path)\n",
    "    print(f\"âœ“ {os.path.basename(file_path)} ({size:,} bytes)\")\n",
    "\n",
    "# Check plot files\n",
    "plot_files = glob.glob(\"../plots/*.png\") + glob.glob(\"../plots/*.json\")\n",
    "print(f\"\\nPlot Files ({len(plot_files)} files):\")\n",
    "for file_path in sorted(plot_files):\n",
    "    size = os.path.getsize(file_path)\n",
    "    print(f\"âœ“ {os.path.basename(file_path)} ({size:,} bytes)\")\n",
    "\n",
    "# Check source files\n",
    "src_files = glob.glob(\"../src/*.py\")\n",
    "print(f\"\\nSource Files ({len(src_files)} files):\")\n",
    "for file_path in sorted(src_files):\n",
    "    size = os.path.getsize(file_path)\n",
    "    print(f\"âœ“ {os.path.basename(file_path)} ({size:,} bytes)\")\n",
    "\n",
    "# Check deployment files  \n",
    "deploy_files = glob.glob(\"../deployment/*.py\")\n",
    "print(f\"\\nDeployment Files ({len(deploy_files)} files):\")\n",
    "for file_path in sorted(deploy_files):\n",
    "    size = os.path.getsize(file_path)\n",
    "    print(f\"âœ“ {os.path.basename(file_path)} ({size:,} bytes)\")\n",
    "\n",
    "print(f\"\\nâœ… Pipeline verification complete!\")\n",
    "print(f\"âœ… All components are functioning correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bd349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate requirements.txt file\n",
    "requirements = [\n",
    "    \"pandas>=1.3.0\",\n",
    "    \"numpy>=1.21.0\", \n",
    "    \"scikit-learn>=1.0.0\",\n",
    "    \"xgboost>=1.5.0\",\n",
    "    \"matplotlib>=3.3.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"flask>=2.0.0\",\n",
    "    \"requests>=2.25.0\"\n",
    "]\n",
    "\n",
    "with open(\"../requirements.txt\", \"w\") as f:\n",
    "    for req in requirements:\n",
    "        f.write(req + \"\\n\")\n",
    "\n",
    "print(\"âœ“ requirements.txt created\")\n",
    "\n",
    "# Generate README.md file\n",
    "readme_content = \"\"\"# Machine Learning Pipeline Project\n",
    "\n",
    "A complete end-to-end machine learning pipeline with data cleaning, feature engineering, model training, evaluation, and deployment.\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "```\n",
    "machine-learning-pipeline/\n",
    "â”‚â”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ raw/                    # Raw data files\n",
    "â”‚   â”œâ”€â”€ processed/              # Processed data files\n",
    "â”‚â”€â”€ notebooks/\n",
    "â”‚   â””â”€â”€ ml_pipeline_complete.ipynb  # Complete pipeline notebook\n",
    "â”‚â”€â”€ src/\n",
    "â”‚   â”œâ”€â”€ data_cleaning.py        # Data cleaning functions\n",
    "â”‚   â”œâ”€â”€ feature_engineering.py  # Feature engineering functions\n",
    "â”‚   â”œâ”€â”€ model_training.py       # Model training functions\n",
    "â”‚   â”œâ”€â”€ model_evaluation.py     # Model evaluation functions\n",
    "â”‚   â””â”€â”€ utils.py               # Utility functions\n",
    "â”‚â”€â”€ models/                     # Trained models and metadata\n",
    "â”‚â”€â”€ deployment/\n",
    "â”‚   â”œâ”€â”€ app.py                 # Flask API application\n",
    "â”‚   â””â”€â”€ test_api.py            # API testing script\n",
    "â”‚â”€â”€ plots/                      # Generated visualizations\n",
    "â”‚â”€â”€ docs/                       # Documentation\n",
    "â”‚â”€â”€ requirements.txt            # Python dependencies\n",
    "â””â”€â”€ README.md                   # This file\n",
    "```\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Data Cleaning**: Handle missing values, duplicates, outliers\n",
    "- **Exploratory Data Analysis**: Comprehensive visualizations and statistics\n",
    "- **Feature Engineering**: One-hot encoding, scaling, feature creation\n",
    "- **Model Training**: Multiple algorithms with hyperparameter tuning\n",
    "- **Model Evaluation**: Comprehensive metrics and comparisons\n",
    "- **Deployment**: Flask API for real-time predictions\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. **Install dependencies:**\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "2. **Run the complete pipeline:**\n",
    "   ```bash\n",
    "   jupyter notebook notebooks/ml_pipeline_complete.ipynb\n",
    "   ```\n",
    "\n",
    "3. **Or run individual modules:**\n",
    "   ```bash\n",
    "   cd src\n",
    "   python data_cleaning.py\n",
    "   python feature_engineering.py\n",
    "   python model_training.py\n",
    "   python model_evaluation.py\n",
    "   ```\n",
    "\n",
    "4. **Start the API server:**\n",
    "   ```bash\n",
    "   cd deployment\n",
    "   python app.py\n",
    "   ```\n",
    "\n",
    "5. **Test the API:**\n",
    "   ```bash\n",
    "   cd deployment\n",
    "   python test_api.py\n",
    "   ```\n",
    "\n",
    "## API Usage\n",
    "\n",
    "The Flask API provides the following endpoints:\n",
    "\n",
    "- `GET /health` - Health check\n",
    "- `GET /model_info` - Model information\n",
    "- `POST /predict` - Make predictions\n",
    "- `GET /predict_sample` - Test with sample data\n",
    "\n",
    "Example prediction request:\n",
    "```json\n",
    "{\n",
    "  \"data\": {\n",
    "    \"age\": 35,\n",
    "    \"income\": 55000,\n",
    "    \"education_years\": 16,\n",
    "    \"experience\": 10,\n",
    "    \"city\": \"New York\",\n",
    "    \"gender\": \"Female\", \n",
    "    \"married\": \"Yes\",\n",
    "    \"credit_score\": 720,\n",
    "    \"loan_amount\": 200000,\n",
    "    \"employment_type\": \"Full-time\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "## Models Supported\n",
    "\n",
    "- Logistic Regression (Classification)\n",
    "- Random Forest (Classification/Regression)\n",
    "- XGBoost (Classification/Regression)\n",
    "\n",
    "## Data Requirements\n",
    "\n",
    "The pipeline is designed to work with any CSV dataset containing:\n",
    "- Mixed numerical and categorical features\n",
    "- 300+ rows recommended\n",
    "- Target variable for supervised learning\n",
    "\n",
    "## Contributing\n",
    "\n",
    "1. Fork the repository\n",
    "2. Create a feature branch\n",
    "3. Make your changes\n",
    "4. Add tests\n",
    "5. Submit a pull request\n",
    "\n",
    "## License\n",
    "\n",
    "This project is licensed under the MIT License.\n",
    "\"\"\"\n",
    "\n",
    "with open(\"../README.md\", \"w\") as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"âœ“ README.md created\")\n",
    "print(\"\\nğŸ‰ Complete ML Pipeline Setup Finished!\")\n",
    "print(\"\\nğŸ“ Project files generated:\")\n",
    "print(\"   âœ“ requirements.txt\")\n",
    "print(\"   âœ“ README.md\") \n",
    "print(\"   âœ“ All source modules in /src\")\n",
    "print(\"   âœ“ Flask API in /deployment\")\n",
    "print(\"   âœ“ Trained models in /models\")\n",
    "print(\"   âœ“ Visualizations in /plots\")\n",
    "print(\"\\nğŸš€ Your ML pipeline is ready to use!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
